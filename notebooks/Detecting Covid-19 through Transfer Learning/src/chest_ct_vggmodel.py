# -*- coding: utf-8 -*-
"""CT_VggModel.ipynb

Automatically generated by Colaboratory.

filename: chest_ct_vggmodel.py
author: Supriya Sudarshan
version: 18.04.2021
description: VGG19 model for detection of Covid-19 in chest CT's

"""

# Basic imports
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
from glob import glob

from tensorflow.keras.models import Model, load_model
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import sys
sys.path.append('/content/drive/MyDrive/Colab Notebooks')

# user defined
from generic_model import *

# Load data paths

covid_path = '/content/drive/MyDrive/Colab Notebooks/CT/CT_COVID'
noncovid_path = '/content/drive/MyDrive/Colab Notebooks/CT/CT_NonCOVID'

covid_files = glob(covid_path + '/*')
noncovid_files = glob(noncovid_path + '/*')

# process image and split it into train and test set
[X_train, X_test, y_train, y_test] = split_images_and_process(covid_files, noncovid_files)

# Base model: VGG19 - Flatten - FC (16) - Dropout (0.2) - Output(2, softmax)
# Optimizer - Adam, Learning rate - 10-3 
# Loss - binary_crossentropy
# metrics - accuracy

model = vgg_model(lr=1e-3, dropout_val=0.2, fc_neurons=16)

model.summary()

# Data Augmentation on Training Set

train_aug = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True
)

# Batch size (bs) = 32
# Epochs = 100
# Early stopping to stop training when a 'val_loss' has stopped improving for 10 consecutive epochs.

bs = 32
epoch = 100

hist = model.fit(train_aug.flow(X_train, y_train, batch_size = bs),
                    validation_data=(X_test, y_test),
                    validation_steps=len(X_test) // bs,
                    steps_per_epoch=len(X_train) // bs,
                    epochs = epoch)

#plot_model_acc_loss(history = hist, title = 'Chest CT Covid Vs Non-Covid')

model.save('/content/drive/MyDrive/Colab Notebooks/saved_models/chest_ct_vggmodel.h5')

# Evaluations

y_pred = model.predict(X_test, batch_size=32)

prediction=y_pred[0:3]
for index, probability in enumerate(prediction):
  if probability[1] > 0.7:
        plt.title('%.2f' % (probability[1]*100) + '% COVID')
  else:
        plt.title('%.2f' % ((1-probability[1])*100) + '% NonCOVID')
  plt.imshow(X_test[index])
  plt.show()

# Convert to binary classes
y_pred_bin = np.argmax(y_pred, axis=1)
y_test_bin = np.argmax(y_test, axis=1)

print('Confusion Matrix')
plot_confusion_matrix(['COVID','NonCOVID'],y_test_bin, y_pred_bin)
report(y_test_bin, y_pred_bin)



"""For a dataset consisting of 397 Non-Covid and 344 Covid images:

Covid: Precision = 0.96, Recall = 0.93, F1 Score = 0.94  
Normal: Precision = 0.94, Recall = 0.96, F1 Score = 0.95  

Average F1 Score: 0.95

Confusion matrix: [[64, 5][3, 77]]

As per the paper for 397 Non-Covid and 349 Covid findings:

Covid : Precision = 0.79, Recall = 0.83, F1 Score = 0.81  
Normal: Precision = 0.84, Recall = 0.81, F1 Score = 0.83  

Average F1 score: 0.78  

Confusion matrix: [[58, 12]
                    [15, 65]]
"""

